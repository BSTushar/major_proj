Hereâ€™s an enhanced version of your `README.md`. Iâ€™ve polished the wording, improved the structure, added clarity, and made it more user-friendly while keeping it professional.

````markdown
# ğŸ™ï¸ Real-Time Speech-to-Text with ASR Performance Analysis

This project is a **web-based application** for real-time speech-to-text transcription. It uses a pre-trained **Automatic Speech Recognition (ASR)** model to transcribe spoken audio directly from the browser.  
Additionally, it provides a **performance evaluation tool** to analyze how well the model performs with different **voice pitches**, using Word Error Rate (WER) as the metric.

---

## âœ¨ Features

- âš¡ **Real-Time Transcription** â€” Stream audio from your microphone and see instant transcriptions.  
- ğŸ¨ **Modern UI** â€” Built with **HTML, CSS, and JavaScript** for a clean, responsive interface.  
- ğŸ§  **Wav2Vec2 Model** â€” Uses Hugging Faceâ€™s **`facebook/wav2vec2-base-960h`** for high-accuracy transcription.  
- ğŸ“Š **Performance Evaluation** â€” Includes a Python script to evaluate ASR accuracy across different pitch variations and generate a **scatter plot graph**.  

---

## âš™ï¸ Prerequisites

Before starting, ensure you have the following installed:

- **Python 3.8+**  
- **Git**  
- **FFmpeg** (required for audio handling)  
  - [Download FFmpeg](https://ffmpeg.org/download.html)  
  - Add the `ffmpeg` executable to your systemâ€™s PATH.  

---

## ğŸš€ Installation

Set up and run the project locally:

1. **Clone the repository**
   ```bash
   git clone https://github.com/BSTushar/major_proj.git
   cd major_proj
````

2. **Create and activate a virtual environment**

   ```bash
   python -m venv venv

   # On Windows
   .\venv\Scripts\activate

   # On macOS/Linux
   source venv/bin/activate
   ```

3. **Install dependencies**

   ```bash
   pip install -r requirements.txt
   ```

---

## ğŸ“‚ Project Structure

```
major_proj/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py              # Flask backend
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html          # Main transcription page
â”‚   â”œâ”€â”€ record_audio.html   # Standalone audio recorder for test data
â”‚   â””â”€â”€ static/
â”‚       â”œâ”€â”€ css/
â”‚       â”‚   â””â”€â”€ style.css
â”‚       â””â”€â”€ js/
â”‚           â””â”€â”€ script.js
â”œâ”€â”€ test_data/
â”‚   â”œâ”€â”€ high_pitch.wav      # Test data (to be generated)
â”‚   â”œâ”€â”€ low_pitch.wav       # Test data (to be generated)
â”‚   â”œâ”€â”€ normal.wav          # Test data (to be generated)
â”‚   â””â”€â”€ transcriptions.txt
â”œâ”€â”€ evaluate.py             # Performance evaluation script
â”œâ”€â”€ run.py                  # Run the Flask server
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## â–¶ï¸ Usage

### 1. Generate Test Audio ğŸ¤

To evaluate performance, youâ€™ll need **clean WAV files** for different pitches.

1. Start the server:

   ```bash
   python run.py
   ```
2. Open `http://127.0.0.1:5000/record` in your browser.
3. Click **Start Recording**, read:
   *â€œThe quick brown fox jumps over the lazy dogâ€*, then click **Stop Recording**.
4. Save three versions:

   * `normal.wav`
   * `high_pitch.wav`
   * `low_pitch.wav`
5. Move them into the `test_data/` folder.

---

### 2. Run the Application ğŸŒ

1. Start the server if not already running:

   ```bash
   python run.py
   ```
2. Open `http://127.0.0.1:5000/` in your browser.
3. Click **Start** and begin speaking.
4. Watch real-time transcriptions appear on screen.

---

### 3. Run the Evaluation Script ğŸ“Š

Once test audio is ready:

```bash
python evaluate.py
```

* Output: **`asr_performance_vs_pitch.png`**
* This scatter plot shows **ASR accuracy vs. pitch variation**.

---

## ğŸ Troubleshooting

| Problem                         | Cause                               | Solution                                        |
| ------------------------------- | ----------------------------------- | ----------------------------------------------- |
| **Could not access microphone** | Browser security restrictions       | Run from `http://127.0.0.1:5000/record`         |
| **FFmpeg error codes**          | FFmpeg not installed or not in PATH | Install FFmpeg and update environment variables |
| **No valid data points**        | Corrupted or invalid WAV files      | Re-record using `record_audio.html`             |

---

## ğŸ“œ License

This project is licensed under the **MIT License**. You are free to use, modify, and distribute it with proper attribution.

---

## ğŸ™Œ Acknowledgements

* [Hugging Face Transformers](https://huggingface.co/transformers/)
* [Wav2Vec2 Base Model](https://huggingface.co/facebook/wav2vec2-base-960h)
* [Flask](https://flask.palletsprojects.com/)
* [FFmpeg](https://ffmpeg.org/)


Would you like me to also **add screenshots/demo GIF instructions** (with placeholders) in the README so that anyone cloning the repo can quickly see how the UI looks?
```
